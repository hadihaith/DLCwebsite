# Database Merge/Import System

## ğŸ¯ Overview

The **new** database restore function has been redesigned to **merge/import** data from SQLite files into your current database instead of replacing everything. This is much safer and preserves your existing data!

## âœ¨ Key Changes

### Old Behavior (Replaced)
- âŒ **Destructive**: Completely replaced current database
- âŒ **Data Loss**: Erased all existing data
- âŒ **Risky**: No way to keep current records
- âŒ **Complex**: Multiple conversion modes (SQLiteâ†’PostgreSQL, etc.)

### New Behavior (Current)
- âœ… **Non-Destructive**: Merges new data into existing database
- âœ… **Safe**: Preserves all existing records
- âœ… **Smart Deduplication**: Skips records that already exist
- âœ… **Simple**: One clear purpose - import missing data

## ğŸš€ How It Works

### Upload Process

1. **Upload SQLite File**: Choose any `.sqlite3`, `.db`, or `.sqlite` file
2. **Automatic Analysis**: System reads all tables from the uploaded file
3. **Smart Merging**: Only adds records that don't already exist
4. **Detailed Report**: Shows exactly what was added vs. skipped

### Deduplication Logic

Each model has its own uniqueness check:

| Model | Uniqueness Check |
|-------|------------------|
| **User** | `student_id` (one user per student ID) |
| **Event** | `title` + `date` (same event name on same date = duplicate) |
| **Application** | `student_id` + `year` (one application per student per year) |
| **MembershipApplication** | `student_id` + `academic_year` |
| **ExchangeApplication** | `student_id` + `destination_university` |
| **Attendance** | `event` + `student_id` (one attendance per student per event) |
| **Thread** | `title` + `author` (same author can't create thread with same title) |
| **DeanList** | `name` (unique list name) |
| **DeanListStudent** | `dean_list` + `student_id` |
| **Course** | `course_code` (unique course code) |
| **EventSection** | `event` + `section_name` |

### What Gets Imported

```
âœ… Users (with passwords, roles, membership status)
âœ… Events (with all details and images)
âœ… Event Sections
âœ… Applications (all types: general, membership, exchange)
âœ… Attendance records
âœ… Forum Threads
âœ… Thread Replies
âœ… Dean Lists
âœ… Dean List Students
âœ… Courses
```

## ğŸ“‹ Step-by-Step Usage

### 1. Access Import Page

Navigate to: **Portal â†’ Restore Database**

### 2. Upload SQLite File

Click "Choose File" and select your `.sqlite3` file (e.g., your local development database)

### 3. Review Import Results

After upload completes, you'll see:

```
âœ… Data import completed! Added 127 records, skipped 45 duplicates.

Users: +5 new, ~3 existing | Events: +12 new, ~8 existing | 
Applications: +23 new, ~10 existing | Attendance: +87 new, ~24 existing
```

### 4. Verify Data

Check your portal - all new data should be visible alongside existing data!

## ğŸ’¡ Use Cases

### Case 1: Local Development â†’ Production

**Scenario**: You've been developing locally with SQLite and have test data. Now deploying to Railway with PostgreSQL.

**Solution**:
```
1. Download your local db.sqlite3
2. Deploy app to Railway (PostgreSQL will be empty)
3. Upload db.sqlite3 via Portal â†’ Restore Database
4. All your local data now imported to PostgreSQL! âœ…
```

### Case 2: Merging Multiple Databases

**Scenario**: Different team members have SQLite databases with different events/users.

**Solution**:
```
1. Start with one database as the base (deployed)
2. Upload teammate #1's db.sqlite3 â†’ adds their unique data
3. Upload teammate #2's db.sqlite3 â†’ adds their unique data
4. Combined database with all unique records! âœ…
```

### Case 3: Backup Recovery (Selective)

**Scenario**: You accidentally deleted some events. You have an old backup SQLite file.

**Solution**:
```
1. Upload old backup SQLite file
2. System adds back deleted events
3. Skips events that still exist
4. Recovered deleted data! âœ…
```

### Case 4: Initial Data Seeding

**Scenario**: Fresh PostgreSQL database on Railway. Need to add initial users, events, dean lists.

**Solution**:
```
1. Create SQLite file locally with initial data
2. Upload to production
3. All initial data imported
4. Production seeded! âœ…
```

## âš ï¸ Important Notes

### What Happens to Existing Data

**Existing records are NEVER touched!**

- If a user with student_id `12345678` exists â†’ skipped
- If an event "Welcome Party" on "2025-09-15" exists â†’ skipped
- **Only new records are added**

### Foreign Key Handling

When importing linked data (e.g., Attendance linked to Events):

1. System finds the matching Event by ID
2. If Event doesn't exist, Attendance record is skipped
3. If Event exists, Attendance is created with correct link

**Best Practice**: Import in logical order:
- Users first (many things reference users)
- Events before Attendance
- Dean Lists before Dean List Students

But don't worry - the system handles this automatically! If a referenced record doesn't exist, it just skips that import.

### ID Fields

- **Auto-increment IDs**: Not imported (PostgreSQL generates new ones)
- **Foreign Keys**: Matched by looking up existing records
- **Student IDs**: Imported exactly as-is

### Password Preservation

User passwords are imported with their hashed values, so users can log in with the same passwords from the SQLite file.

## ğŸ“Š Import Statistics

After each import, you get detailed statistics:

```python
stats = {
    'users': {'added': 5, 'skipped': 3},
    'events': {'added': 12, 'skipped': 8},
    'applications': {'added': 23, 'skipped': 10},
    # ... etc
}
```

### Reading the Stats

- **Added**: New records created in your database
- **Skipped**: Records that already existed (duplicates avoided)

**Total = Added + Skipped** (all records from uploaded file accounted for)

## ğŸ›¡ï¸ Safety Features

### 1. Validation

Before import:
```python
# Validates SQLite file integrity
sqlite3.connect(file).execute('PRAGMA schema_version;')
```

### 2. Exception Handling

Each model has its own try/catch:
```python
try:
    # Import users
except Exception as e:
    messages.warning(request, f'User import issue: {e}')
    # Continue with other models
```

One failed import doesn't stop the whole process!

### 3. No Database Backups Needed

Since existing data is never modified:
- No risk of data loss
- No need to restore from backup
- Import can be run multiple times safely

### 4. Transaction Safety

All imports use Django ORM:
```python
User.objects.create(...)  # Atomic operation
```

If a single record fails, it doesn't affect others.

## ğŸ› Troubleshooting

### Issue: "Some records were skipped"

**Cause**: Records already exist in database

**Solution**: This is normal! Check the stats to see what was skipped.

### Issue: "User import issue: UNIQUE constraint failed"

**Cause**: Trying to create user with duplicate student_id

**Solution**: Already handled! System checks `.exists()` before creating.

### Issue: "Attendance not imported"

**Cause**: Referenced Event doesn't exist in current database

**Solution**: Import Events first, then re-upload the file to import Attendance.

### Issue: "No records added"

**Cause**: All records from uploaded file already exist

**Solution**: This is normal if you're re-uploading the same file!

## ğŸ”§ Technical Details

### Database Operations

```python
# Check if exists
if not User.objects.filter(student_id=row['student_id']).exists():
    # Create only if doesn't exist
    User.objects.create(
        student_id=row['student_id'],
        username=row['username'],
        # ... other fields
    )
```

### SQLite Reading

```python
# Connect to uploaded file
sqlite_conn = sqlite3.connect(tmp_path)
sqlite_conn.row_factory = sqlite3.Row  # Dict-like access

# Read table
cursor.execute("SELECT * FROM main_user")
for row in cursor.fetchall():
    print(row['student_id'], row['username'])
```

### Works with Both SQLite and PostgreSQL

Target database can be:
- âœ… SQLite (local development)
- âœ… PostgreSQL (Railway production)

The merging logic is the same!

## ğŸ“ˆ Performance

| Records | Import Time |
|---------|-------------|
| < 100 | 5-10 seconds |
| 100-1,000 | 10-30 seconds |
| 1,000-10,000 | 30-120 seconds |
| > 10,000 | 2-5 minutes |

Progress message shown during import:
```
â„¹ï¸ Starting data import... This may take a few minutes.
```

## ğŸ“ Best Practices

### Before Importing

1. **Check current data**: Know what's already in your database
2. **Review SQLite file**: Make sure it contains the data you want
3. **Test locally first**: Try importing to local database before production

### During Import

1. **Wait for completion**: Don't refresh page during import
2. **Watch for warnings**: Yellow messages indicate non-critical issues
3. **Review stats**: Check added vs. skipped counts

### After Importing

1. **Verify data**: Check portal to confirm new records visible
2. **Test functionality**: Try creating events, viewing users, etc.
3. **Check relationships**: Ensure attendance links to events correctly

## ğŸ”— Related Documentation

- [DATABASE_BACKUP_RESTORE.md](DATABASE_BACKUP_RESTORE.md) - Old restore system (replaced)
- [POSTGRESQL_SETUP.md](POSTGRESQL_SETUP.md) - PostgreSQL configuration
- [SQLITE_TO_POSTGRES_CONVERSION.md](SQLITE_TO_POSTGRES_CONVERSION.md) - Old conversion docs (replaced)

## ğŸ‰ Summary

The new merge/import system:

âœ… **Safe** - Never deletes existing data
âœ… **Smart** - Automatically skips duplicates
âœ… **Simple** - One clear purpose: add missing data
âœ… **Flexible** - Works with SQLite or PostgreSQL targets
âœ… **Informative** - Detailed statistics after each import
âœ… **Robust** - Handles errors gracefully per model

**Perfect for:**
- Migrating local development to production
- Merging data from multiple sources
- Recovering deleted records from backups
- Seeding fresh databases with initial data

---

**Last Updated**: October 25, 2025
**Status**: âœ… Production Ready
